{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a028243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np \n",
    "#import Holistic\n",
    "import mediapipe as mp\n",
    "# window에서만 지원 \n",
    "#from win10toast import ToastNotifier\n",
    "import math\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940a2105-2379-4173-969d-779d631d3d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# mp_drawing_styles = mp.solutions.drawing_styles\n",
    "# mp_pose = mp.solutions.pose\n",
    "\n",
    "# #파일 위치 미리 지정\n",
    "# input_video_path = \"./data/ex3_input.mp4\"\n",
    "# default_video_path = \"./data/ex3_default.mp4\"\n",
    "# save_video_path = './output/ex3_output.mp4'\n",
    "\n",
    "# cap = cv2.VideoCapture(input_video_path)\n",
    "# # webcam으로 할 경우엔 input_video_path 대신 0을 넣어줄 것\n",
    "# # cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # holistic = Holistic.HolisticDetector()\n",
    "# mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39378c22-ec85-4015-8994-4c9acd1686cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "#파일 위치 미리 지정\n",
    "input_video_path = \"./data/ex4_input.mp4\"\n",
    "#default_video_path = \"./data/ex3_default.mp4\"\n",
    "save_video_path = './output/ex4_holistic_output.mp4'\n",
    "#save_default_video_path = './output/ex3_holistic_default_output.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "#cap_d = cv2.VideoCapture(default_video_path)\n",
    "# webcam으로 할 경우엔 input_video_path 대신 0을 넣어줄 것\n",
    "# cap = cv2.VideoCapture(0)\n",
    "#holistic = Holistic.HolisticDetector()\n",
    "\n",
    "#재생할 파일의 넓이와 높이\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "#video controller\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter(save_video_path, fourcc, 30.0, (int(width), int(height)))\n",
    "#out_d = cv2.VideoWriter(save_default_video_path, fourcc, 30.0, (int(width), int(height)))  ####\n",
    "\n",
    "######\n",
    "# records_d = {}\n",
    "# records_d['fn'], records_d['us'], records_d['rs'] = [], [], []\n",
    "\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     while cap_d.isOpened():\n",
    "#         success, image = cap_d.read()\n",
    "#         #print(success, image)\n",
    "#         # Webcam 사용 시 이 코드 살리기 \n",
    "#         # if not success:\n",
    "#         #     print(\"카메라를 찾을 수 없습니다.\")\n",
    "#         #     # 웹캠을 불러올 경우는 'continue', 동영상을 불러올 경우 'break'를 사용합니다.\n",
    "#         if success:  \n",
    "#             image.flags.writeable = False\n",
    "#             image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#             results_d = holistic.process(image)\n",
    "    \n",
    "#             # 포즈 주석을 이미지 위에 그립니다.\n",
    "#             image.flags.writeable = True\n",
    "#             image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "#             #image = cv2.blur(image, (75, 75))\n",
    "#             mp_drawing.draw_landmarks(image, results_d.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "#             mp_drawing.draw_landmarks(image, results_d.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "#                                       landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "            \n",
    "#             face_lm, pose_lm = save_landmarks(results_d, image, min_lm=True)\n",
    "#             fn, sh_angle, rs = summary_records(face_lm, pose_lm)\n",
    "            \n",
    "#             records_d['fn'].append(fn)\n",
    "#             records_d['us'].append(sh_angle)\n",
    "#             records_d['rs'].append(rs)\n",
    "            \n",
    "#             out.write(image)\n",
    "#         else: \n",
    "#             break\n",
    "\n",
    "# cap_d.release()\n",
    "# out_d.release()\n",
    "########\n",
    "\n",
    "records = {}\n",
    "records['fn'], records['us'], records['rs'] = [], [], []\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        #print(success, image)\n",
    "        # Webcam 사용 시 이 코드 살리기 \n",
    "        # if not success:\n",
    "        #     print(\"카메라를 찾을 수 없습니다.\")\n",
    "        #     # 웹캠을 불러올 경우는 'continue', 동영상을 불러올 경우 'break'를 사용합니다.\n",
    "        if success:  \n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(image)\n",
    "    \n",
    "            # 포즈 주석을 이미지 위에 그립니다.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            #image = cv2.blur(image, (75, 75))\n",
    "            mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                      landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "            \n",
    "            face_lm, pose_lm = save_landmarks(results, image, min_lm=True)\n",
    "            fn, sh_angle, rs = summary_records(face_lm, pose_lm)\n",
    "            \n",
    "            records['fn'].append(fn)\n",
    "            records['us'].append(sh_angle)\n",
    "            records['rs'].append(rs)\n",
    "            \n",
    "            out.write(image)\n",
    "        else: \n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540c4a8c-540b-497f-b781-0c51bafc1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_landmarks(results, image, min_lm=False):\n",
    "    lms = [results.face_landmarks.landmark, results.pose_landmarks.landmark]\n",
    "    face_lm, pose_lm = {}, {} \n",
    "    lm_list = [face_lm, pose_lm]\n",
    "    h, w, c, = image.shape # height, width, channel\n",
    "    \n",
    "    for num in range(len(lms)):\n",
    "        lm = lms[num]\n",
    "        if min_lm == True:\n",
    "            # Save only essential 5 landmarks for reducing required time\n",
    "            # Essential landmarks: Face = 152, 133, 362 / Pose = 12, 11\n",
    "            cds = lm\n",
    "            if num == 0: # Face landmarks\n",
    "                lm_list[num][152] = (cds[152].x, cds[152].y, cds[152].z)\n",
    "                lm_list[num][133], lm_list[num][362] = (cds[133].x, cds[133].y, cds[133].z), (cds[362].x, cds[362].y, cds[362].z)\n",
    "            else: # Pose landmarks\n",
    "                lm_list[num][11], lm_list[num][12] = (cds[11].x, cds[11].y, cds[11].z), (cds[12].x, cds[12].y, cds[12].z)\n",
    "        else:\n",
    "            # Save all the landmarks\n",
    "            for i, cd in enumerate(lm):\n",
    "                cx, cy, cz = int(cd.x*w), int(cd.y*h), int(cd.z*(w+h)/2)\n",
    "                cxyz = (cx, cy, cz)\n",
    "                lm_list[num][i] = cxyz\n",
    "    return face_lm, pose_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a707e83b-63e5-43fc-b772-27aa3b6d1976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(p1, p2): \n",
    "    dx = (p1[0] - p2[0]) ** 2\n",
    "    dy = (p1[1] - p2[1]) ** 2\n",
    "    eu_dist = (dx + dy) ** 0.5\n",
    "    return eu_dist\n",
    "\n",
    "def summary_records(face_lm, pose_lm):\n",
    "    # Distace between two eyes\n",
    "    a = euclidean_dist(face_lm[133], face_lm[362])\n",
    "    \n",
    "    # Length of neck     \n",
    "    mid_sh = ((pose_lm[11][0]+pose_lm[12][0])/2, (pose_lm[11][1]+pose_lm[12][1])/2)\n",
    "    b = euclidean_dist(face_lm[152], mid_sh)\n",
    "    \n",
    "    # Shoulder angle \n",
    "    c = euclidean_dist(pose_lm[11], pose_lm[12])\n",
    "    if pose_lm[11][1] > pose_lm[12][1]:\n",
    "        sh_flag = 'Right' # 오른쪽 어깨가 아래 \n",
    "        c_x = euclidean_dist(pose_lm[12], (pose_lm[11][0], pose_lm[12][1]))\n",
    "        c_y = euclidean_dist(pose_lm[11], (pose_lm[11][0], pose_lm[12][1]))\n",
    "    \n",
    "    else: # pose_lm[11][1] < pose_lm[12][1]\n",
    "        sh_flag = 'Left'  # 왼쪽 어깨가 아래 \n",
    "        c_x = euclidean_dist(pose_lm[11], (pose_lm[12][0], pose_lm[11][1]))\n",
    "        c_y = euclidean_dist(pose_lm[12], (pose_lm[12][0], pose_lm[11][1])) \n",
    "    \n",
    "    sh_angle = np.degrees(np.arccos(c_x/c))\n",
    "    fn = b / a\n",
    "    rs =  c / a\n",
    "    return fn, sh_angle, rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d0cc8-35d8-4162-b4b9-748d810eae88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holistic",
   "language": "python",
   "name": "holistic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
